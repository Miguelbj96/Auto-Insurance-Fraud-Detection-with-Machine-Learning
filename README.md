## üöÄ Trabajo con las siguientes tecnolog√≠as:  
<img  alt="python" src ="https://img.shields.io/badge/Python-14354C?style=for-the-badge&logo=python&logoColor=white"/>

##  üë®üèΩ‚Äçüíº Transformando sospechas en decisiones con Machine Learning üë©üèΩ‚Äçüíº
Predicci√≥n de fraude en reclamos de seguros

En el a√±o 2023, una aseguradora de Colombia registr√≥ m√°s de 24.000 fraudes, sumando p√©rdidas de m√°s de 62 millones de d√≥lares. Si pensamos que cada fraude cost√≥ m√°s de $2.500 en promedio
<div align="center"> ¬øC√≥mo podemos anticiparnos a estos eventos antes de que ocurran? </div>

<div align="center">
  <img height="420"  src="https://github.com/EmilioQuimisM/EmilioQuimisM/blob/main/que%20hace%20el%20modelo.png" alt="Card header"/> 
</div>

## Metodolog√≠a - An√°lisis Exploratorio
El dataset consta de 15,420 registros y 33 columnas, con una mayor√≠a de variables de tipo categ√≥rico.
La mayor√≠a de las variables son categ√≥ricas (25) y el resto num√©ricas (8)
Hallazgo Relevante 1 (Desbalance de Clases): La variable objetivo FraudFound presenta un fuerte desbalance, con solo un 6% de los casos etiquetados como fraude. Esto implica la necesidad de t√©cnicas espec√≠ficas para el modelado.
Hallazgo Relevante 2 (Valores Inv√°lidos): Se identificaron valores inv√°lidos como "0" en columnas de fecha (DayOfWeekClaimed, MonthClaimed), los cuales requerir√°n limpieza.
Hallazgo Relevante 3 (Baja Variabilidad): Variables como WitnessPresent,AgentType, AddressChange-Claim y NumberOfCars mostraron baja variabilidad, lo que sugiere un potencial bajo poder predictivo (aunque se mantuvieron para evaluaci√≥n con SHAP).
Algunas variables categ√≥ricas (Make, Fault, VehiclePrice, etc.) muestran diferencias visuales claras entre clases, lo que indica potencial valor predictivo.

<div align="center">
  <img height="320"  src="https://github.com/EmilioQuimisM/EmilioQuimisM/blob/main/Metodolog%C3%ADa%20-%20An%C3%A1lisis%20Exploratorio.png" alt="Card header"/> 
</div>

## Metodolog√≠a - Procesamiento de Datos

Se identificaron 320 registros con un valor de "0" en la variable Age. Para preservar la informaci√≥n de estos registros, en lugar de eliminarlos, se opt√≥ por la imputaci√≥n utilizando la mediana de la edad dentro del grupo correspondiente de AgeOfPolicyHolder
Manejo de Valores Inv√°lidos: Se eliminaron los registros con valores "0" en DayOfWeekClaimed y MonthClaimed ya que no representan datos v√°lidos.
Eliminaci√≥n de Columnas: Se eliminaron PolicyNumber (ID √∫nico sin valor predictivo), Year (baja variabilidad), Month, Age, RepNumber, y PolicyType (siguiendo indicaciones del tutor).
Manejo de Duplicados: Se elimin√≥ una fila duplicada para asegurar la integridad de los datos.
Correcci√≥n de Inconsistencias: Se unificaron entradas inconsistentes en la columna Make (ej., 'Accura' a 'Acura').
Feature Engineering: Se crearon nuevas variables como ClaimLag, HighRiskProfile, IsSingleYoung, ExpensiveVehicle, WeekendClaim para extraer informaci√≥n potencialmente predictiva.
Codificaci√≥n de Variables Categ√≥ricas: Las variables categ√≥ricas se transformaron a un formato num√©rico utilizando la t√©cnica de one-hot encoding (pd.get_dummies).

<div align="center">
  <img height="320"  src="https://github.com/EmilioQuimisM/EmilioQuimisM/blob/main/Metodolog%C3%ADa%20-%20Procesamiento%20de%20Datos.png" alt="Card header"/> 
</div>

## Metodolog√≠a - Entrenamiento y Tuneo de Hiperpar√°metros

El dataset se dividi√≥ en conjuntos de entrenamiento (60%), validaci√≥n (20%) y prueba (20%) manteniendo la proporci√≥n de la clase objetivo (estratificaci√≥n).
El dataset presenta un desequilibrio considerable en la variable objetivo, donde los casos de fraude comprenden menos del 7% del total de las instancias. Esta distribuci√≥n desigual de clases, que calificamos como un desequilibrio severo.
Se probaron varios algoritmos de clasificaci√≥n: CatBoost, XGBoost, LightGBM, RandomForest y BalancedBagging.
Si bien el AUC obtenido con class_weight (0.794) y undersampling (0.811) es aceptable dada la baja proporci√≥n de fraudes (6%), el AUC excesivamente alto de SMOTE (0.995) apunta a un probable sobreajuste o una posible fuga de informaci√≥n durante la validaci√≥n cruzada.
Se aplic√≥ submuestreo aleatorio (RandomUnderSampler) en el conjunto de entrenamiento para mitigar el desbalance de clases.
Se realiz√≥ una b√∫squeda aleatoria (RandomizedSearchCV) con validaci√≥n cruzada estratificada (5 folds) para encontrar los hiperpar√°metros √≥ptimos para cada modelo, utilizando la m√©trica F1-score como principal criterio de optimizaci√≥n debido al desbalance de clases y la necesidad de un equilibrio entre precisi√≥n y recall. Sin embargo, dada la prioridad de no dejar pasar fraudes, se prest√≥ especial atenci√≥n al recall.

<div align="center">
  <img height="320"  src="https://github.com/EmilioQuimisM/EmilioQuimisM/blob/main/Metodolog%C3%ADa%20-%20Entrenamiento%20y%20Tuneo%20de%20Hiperpar%C3%A1metros.png" alt="Card header"/> 
</div>

## Metodolog√≠a - Interpretabilidad/Explicabilidad del Modelo

Se utiliz√≥ la librer√≠a SHAP (SHapley Additive exPlanations) para comprender la importancia de las variables en las predicciones de los 3 modelos XGBoost, LightGBM y CatBoost(el de mejor rendimiento).
Se generaron gr√°ficos de resumen (summary plots) para visualizar tanto la importancia de las features como la direcci√≥n de su impacto en la predicci√≥n de fraude.
El alto valor predictivo de variables como Fault_Third Party y BasePolicy_Liability sugiere que el fraude puede estar m√°s relacionado con la naturaleza del contrato y no tanto con el perfil personal.
Ejemplo de Insight: La variable Fault_Third Party mostr√≥ ser una de las m√°s importantes, con valores altos (cuando la culpa es del tercero) empujando la predicci√≥n hacia fraude, lo cual tiene sentido de negocio.
Pruebas Fallidas: Se exploraron diferentes t√©cnicas de sobremuestreo (SMOTE) para el desbalance de clases, pero los resultados sugirieron un posible sobreajuste, por lo que se opt√≥ por el submuestreo aleatorio.
la probabilidad de fraude predicha por CatBoost estuvo considerablemente m√°s alejada del punto de decisi√≥n (el umbral) en la direcci√≥n de "no fraude" que las predicciones de XGBoost y LightGBM. Esto sugiere que CatBoost encontr√≥ caracter√≠sticas en esta reclamaci√≥n que lo llevaron a una conclusi√≥n m√°s firme de que no se trataba de un caso fraudulento.

<div align="center">
  <img height="320"  src="https://github.com/EmilioQuimisM/EmilioQuimisM/blob/main/Metodolog%C3%ADa%20-%20Interpretabilidad%20Explicabilidad%20del%20Modelo.png" alt="Card header"/> 
</div>

## Resultados - Rendimiento

Finalmente, se procede a re-entrenar y evaluar los modelos CatBoost, XGBoost y LightGBM utilizando √∫nicamente las 14 variables m√°s importantes identificadas mediante el an√°lisis de interpretabilidad SHAP.
Se re-entrena el modelo utilizando el conjunto de entrenamiento reducido (X_train_reduced) y las etiquetas de entrenamiento balanceadas (y_resampled).
Se realizan predicciones sobre el conjunto de prueba reducido (X_test_reduced).
Se calculan y se imprimen el √°rea bajo la curva ROC (ROC AUC) y el informe de clasificaci√≥n (classification_report), que incluye precisi√≥n, recall, F1-score y soporte para cada clase (no fraude y fraude).

El modelo CatBoost original (entrenado con todas las variables) fue finalmente seleccionado como el mejor debido a su mejor ROC AUC(0.8066) en test set, manteniendo un recall alto (96.2%) que el resto sin una p√©rdida significativa en el F1-score en comparaci√≥n con los modelos entrenados solo con las variables importantes.

<div align="center">
  <img height="320"  src="https://github.com/EmilioQuimisM/EmilioQuimisM/blob/main/Resultados%20-%20Rendimiento.png" alt="Card header"/> 
</div>


## Implementaci√≥n en el Negocio
<div align="center"> Propuesta  </div>
El modelo CatBoost se integrar√≠a en el sistema de gesti√≥n de reclamaciones de la aseguradora. Cada nueva reclamaci√≥n ser√≠a evaluada por el modelo en tiempo real o por lotes peri√≥dicos.

<div align="center"> Justificaci√≥n </div>

<div align="center"> Eficiencia, Reducci√≥n de P√©rdidas y Pr√°cticas Similares
</div>

<div align="center">
  <img height="320"  src="https://github.com/EmilioQuimisM/EmilioQuimisM/blob/main/Implementaci%C3%B3n%20en%20el%20Negocio.png" alt="Card header"/> 
</div>


## Conclusiones y Recomendaciones
<p align="center"> <div align="center"> Conclusi√≥n </div> </p>
 El proyecto demostr√≥ la viabilidad de utilizar un modelo de machine learning (CatBoost) para la detecci√≥n de fraudes en seguros de autos, logrando un alto recall en la identificaci√≥n de casos fraudulentos y un potencial impacto econ√≥mico positivo significativo.
<p align="center"> <div align="center"> Recomendaciones </div> </p>
Explorar t√©cnicas m√°s avanzadas para el manejo de desbalance de clases (ej., algoritmos sensibles al costo, generaci√≥n de datos sint√©ticos m√°s sofisticada).
Investigar la incorporaci√≥n de otras fuentes de datos relevantes que puedan mejorar la capacidad predictiva del modelo.
Experimentar con arquitecturas de modelos m√°s complejas o ensambles de modelos que puedan mejorar el equilibrio entre precisi√≥n y recall.
Invertir en la recopilaci√≥n y el almacenamiento de datos m√°s detallados y diversos sobre los asegurados y las reclamaciones.
Establecer un proceso claro para la revisi√≥n y retroalimentaci√≥n de los casos clasificados como de alto riesgo para mejorar continuamente el modelo y comprender mejor los patrones de fraude.
Evaluar el costo-beneficio de ajustar el umbral de clasificaci√≥n para equilibrar la detecci√≥n de fraudes con el costo de los falsos positivos. </div> </p>

## üåç Conectemos  
# Miguel Brionesüë®üèΩ‚Äçüíª
<a href="mailto:miguelbrionesjara@gmail.com" target="_blank"><img height="28" src = "https://img.shields.io/badge/gmail-c14438?&style=for-the-badge&logo=gmail&logoColor=white"></a>
<a href="https://www.linkedin.com/in/miguel-angel-briones-jara-4308471b7" target="_blank"> <img height="28" src = "https://img.shields.io/badge/-LinkedIn-0e76a8?style=for-the-badge&logo=Linkedin&logoColor=white"></a>
# Jemima Moreira üë©üèΩ‚Äçüíª
<a href="mailto:jhemy321@hotmail.com" target="_blank"><img height="28" src = "https://img.shields.io/badge/gmail-c14438?&style=for-the-badge&logo=gmail&logoColor=white"></a>
<a href="https://www.linkedin.com/in/jemimamoreiraguzman/" target="_blank"> <img height="28" src = "https://img.shields.io/badge/-LinkedIn-0e76a8?style=for-the-badge&logo=Linkedin&logoColor=white"></a>
# Emilio Quimis üë®üèΩ‚Äçüíª
<a href="mailto:emilioqm89@gmail.com" target="_blank"><img height="28" src = "https://img.shields.io/badge/gmail-c14438?&style=for-the-badge&logo=gmail&logoColor=white"></a>
<a href="https://www.linkedin.com/in/emilio-andres-quimis-muentes-569565196" target="_blank"> <img height="28" src = "https://img.shields.io/badge/-LinkedIn-0e76a8?style=for-the-badge&logo=Linkedin&logoColor=white"></a>
# Juan Palacios üë®üèΩ‚Äçüíª
<a href="mailto:juanpadani05@gmail.com" target="_blank"><img height="28" src = "https://img.shields.io/badge/gmail-c14438?&style=for-the-badge&logo=gmail&logoColor=white"></a>
<a href="https://www.linkedin.com/in/juan-carlos-palacios-sachez-6a748240/" target="_blank"> <img height="28" src = "https://img.shields.io/badge/-LinkedIn-0e76a8?style=for-the-badge&logo=Linkedin&logoColor=white"></a>
